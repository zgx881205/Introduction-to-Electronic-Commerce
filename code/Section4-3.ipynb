{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 随机生成聚类中心点  \n",
    "#参数：dataSet-List列表，已分类点坐标\n",
    "#      k-整数，近邻数量\n",
    "#返回值：centroids-2维列表，k个随机中心点坐标\n",
    "def initCentroids(dataSet, k):  \n",
    "    numSamples, dim = dataSet.shape  \n",
    "    centroids = np.zeros((k, dim))  \n",
    "    for i in range(k):  \n",
    "        index = int(np.random.uniform(0, numSamples))  \n",
    "        centroids[i, :] = dataSet[index, :]  \n",
    "    return centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 计算欧式距离，即两点间的直线距离 \n",
    "#参数：vector1-List列表，n维属性坐标值构成的向量\n",
    "#      vector2-List列表，n维属性坐标值构成的向量\n",
    "#返回值：浮点数，欧式距离\n",
    "def euclDistance(vector1, vector2):  \n",
    "    return np.sqrt(np.sum(np.power(vector2 - vector1, 2)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# K均值聚类\n",
    "#参数：dataSet-List列表，待聚类样本集\n",
    "#      k-整数，近邻数量\n",
    "#返回值：centroids-2维列表，k个随机中心点坐标\n",
    "#        clusterAssment -列表，各个样本点的聚类结果\n",
    "def kmeans(dataSet, k):  \n",
    "    numSamples = dataSet.shape[0]\n",
    "#第一列数据存放归属的点\n",
    "#第二列存放样本与候选聚类中心点之间的误差  \n",
    "    clusterAssment = np.mat(np.zeros((numSamples, 2)))  \n",
    "    clusterChanged = True    \n",
    "    centroids = initCentroids(dataSet, k)  \n",
    "  \n",
    "    while clusterChanged:  \n",
    "        clusterChanged = False  \n",
    "        for i in range(numSamples):  \n",
    "            minDist  = 100000.0  \n",
    "            minIndex = 0  \n",
    "#依次找出最近候选聚类中心点\n",
    "            for j in range(k):  \n",
    "                distance = euclDistance(centroids[j, :], dataSet[i, :])  \n",
    "                if distance < minDist:  \n",
    "                    minDist  = distance  \n",
    "                    minIndex = j  \n",
    "#更新归属结果\n",
    "            if clusterAssment[i, 0] != minIndex:  \n",
    "                clusterChanged = True  \n",
    "                clusterAssment[i, :] = minIndex, minDist**2  \n",
    "#更新候选聚类中心点坐标\n",
    "        for j in range(k):  \n",
    "            pointsInCluster = dataSet[np.nonzero(clusterAssment[:, 0].A == j)[0]]  \n",
    "            centroids[j, :] = np.mean(pointsInCluster, axis = 0)  \n",
    "  \n",
    "    print('KMN聚类完成!')  \n",
    "    return centroids, clusterAssment  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2维平面显示聚类结果\n",
    "#参数：dataSet-List列表，样本集\n",
    "#      k-整数，近邻数量\n",
    "#      centroids-List列表，聚类中心点坐标\n",
    "#      clusterAssment-List列表，聚类结果\n",
    "#返回值：无\n",
    "def showCluster(dataSet, k, centroids, clusterAssment):  \n",
    "    fig_2d_clustered=plt.figure()\n",
    "    ax2d_clustered=fig_2d_clustered.add_subplot(111) \n",
    "    \n",
    "    numSamples, dim = dataSet.shape  \n",
    "    if dim != 2:  \n",
    "        print(\"只能绘制2维图形\")  \n",
    "        return 1  \n",
    "#创建数据点标记格式控制列表，实现数据点区别输出\n",
    "    mark = ['.r', '+b', '*g', '1k', '^r', 'vr', 'sr', 'dr', '<r', 'pr']  \n",
    "    if k > len(mark):  \n",
    "        print(\"K值过大！\")  \n",
    "        return 1  \n",
    "#绘制所有样本点\n",
    "    for i in range(numSamples):  \n",
    "        markIndex = int(clusterAssment[i, 0])  \n",
    "        ax2d_clustered.plot(dataSet[i, 0], dataSet[i, 1], mark[markIndex])  \n",
    "\n",
    "#绘制聚类中心点  \n",
    "    for i in range(k):\n",
    "        ax2d_clustered.plot(centroids[i, 0], centroids[i, 1], mark[i], markersize = 20)  \n",
    " \n",
    "    fig_2d_clustered.savefig('4_3:clusterRes.png', dpi=300, bbox_inches='tight')\n",
    "    fig_2d_clustered.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1: 读入数据：\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '4_3:testSet.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-b7916410a161>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"step 1: 读入数据：\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdataSetKMN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfileIn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'4_3:testSet.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfileIn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mlineArr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '4_3:testSet.txt'"
     ]
    }
   ],
   "source": [
    "#调用以上函数，对读入数据进行聚类\n",
    "print(\"step 1: 读入数据：\")  \n",
    "dataSetKMN = []  \n",
    "fileIn = open('Section4-3 testSet.txt')  \n",
    "for line in fileIn.readlines():  \n",
    "    lineArr = line.strip().split(' ')  \n",
    "    dataSetKMN.append([float(lineArr[0]), float(lineArr[1])])  \n",
    "dataSetKMNSize = len(dataSetKMN)\n",
    "dataSetKMN = np.mat(dataSetKMN)\n",
    "for i in range(dataSetKMNSize):\n",
    "    plt.plot(dataSetKMN[i, 0], dataSetKMN[i, 1],'b*') \n",
    "print(\"原始数据分布：\") \n",
    "plt.savefig('4_3:_kmn_orig.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#K取值4，调用K均值算法聚类\n",
    "print(\"step 2: 聚类\")    \n",
    "k = 4\n",
    "centroids, clusterAssment = kmeans(dataSetKMN, k) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"step 3: 结果输出：\")  \n",
    "showCluster(dataSetKMN, k, centroids, clusterAssment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#计算代价TC\n",
    "#参数：dataSet-List列表，样本集\n",
    "#      k-整数，近邻数量\n",
    "#      medoids_idx-List列表，候选中心点\n",
    "#      clusterAssment-List列表，聚类结果\n",
    "#返回值：total_cost-浮点数，TC代价\n",
    "#        medoids-List2维列表，本次归属到各中心点的样本点\n",
    "def totalcost(dataSet, medoids_idx) :\n",
    "    distances_cache = {}\n",
    "    size = len(dataSet)\n",
    "    total_cost = 0.0\n",
    "    medoids = {}\n",
    "    for idx in medoids_idx :\n",
    "        medoids[idx] = []\n",
    "    for i in range(size) :\n",
    "        choice = None\n",
    "        min_cost = 100000\n",
    "#计算各样本数据点到medoids_idx的距离，将其归属到距离最近的那个中心点\n",
    "        for m in medoids :\n",
    "            tmp = distances_cache.get((m,i),None)\n",
    "            if tmp == None :\n",
    "                tmp = euclDistance(dataSet[m],dataSet[i])\n",
    "                distances_cache[(m,i)] = tmp\n",
    "            if tmp < min_cost :\n",
    "                choice = m\n",
    "                min_cost = tmp\n",
    "        medoids[choice].append(i)\n",
    "        total_cost += min_cost\n",
    "    return total_cost, medoids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# K中心点聚类\n",
    "#参数：dataSet-List列表，待聚类样本集\n",
    "#      k-整数，近邻数量\n",
    "#返回值：centroids-2维列表，k个随机中心点坐标\n",
    "#        clusterAssment -列表，各个样本点的聚类结果\n",
    "\n",
    "import random\n",
    "\n",
    "def kmedoids(dataSet, k) :\n",
    "    size ,dim= dataSet.shape\n",
    "    centroids = np.zeros((k,dim))\n",
    "    clusterAssment = np.mat(np.zeros((size, 2)))    \n",
    "    medoids_idx = random.sample([i for i in range(size)], k)\n",
    "    pre_cost, medoids = totalcost(dataSet,medoids_idx)\n",
    "    current_cost = 100000    \n",
    "    best_choice = []\n",
    "    best_res = {}\n",
    "    iter_count = 0\n",
    "#反复计算TC，进行聚类\n",
    "    while 1 :\n",
    "        for m in medoids :\n",
    "            for item in medoids[m] :\n",
    "                if item != m :\n",
    "                    idx = medoids_idx.index(m)\n",
    "                    swap_temp = medoids_idx[idx]\n",
    "                    medoids_idx[idx] = item\n",
    "                    tmp,medoids_ = totalcost(dataSet,medoids_idx)\n",
    "                    if tmp < current_cost :\n",
    "                        best_choice = list(medoids_idx)\n",
    "                        best_res = dict(medoids_)\n",
    "                        current_cost = tmp\n",
    "                    medoids_idx[idx] = swap_temp\n",
    "        iter_count += 1\n",
    "        if best_choice == medoids_idx : break\n",
    "        if current_cost <= pre_cost :\n",
    "            pre_cost = current_cost\n",
    "            medoids = best_res\n",
    "            medoids_idx = best_choice\n",
    "    \n",
    "    centNum=0;\n",
    "    for index in best_choice:\n",
    "        centroids[centNum,:]=dataSet[index,:]\n",
    "        centNum += 1\n",
    "    \n",
    "    classNumber = 0\n",
    "    for key in best_res:\n",
    "        for index in best_res[key]:\n",
    "            clusterAssment[index,0]=classNumber\n",
    "        classNumber += 1\n",
    "      \n",
    "    print('KMed聚类完成!')  \n",
    "    return centroids, clusterAssment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"K中心点算法聚类:\")  \n",
    "dataSetKMed = []  \n",
    "fileIn = open('Section4-3 testSet.txt')  \n",
    "for line in fileIn.readlines():  \n",
    "    lineArr = line.strip().split(' ')  \n",
    "    dataSetKMed.append([float(lineArr[0]), float(lineArr[1])])  \n",
    "dataSetKMedSize = len(dataSetKMed)\n",
    "dataSetKMed = np.mat(dataSetKMed)\n",
    "#K取值4，调用K中心点算法聚类\n",
    "k = 4\n",
    "centroids, clusterAssment = kmedoids(dataSetKMed,k) \n",
    "showCluster(dataSetKMed, k, centroids, clusterAssment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_origin = pd.read_csv('4_3:Mall_Customers.csv',encoding='gb2312')\n",
    "print('原始数据头5行：')\n",
    "print(X_origin.shape)\n",
    "print(X_origin.head())\n",
    "\n",
    "X = X_origin.drop(['ID','性别'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "X_scaled = preprocessing.scale(X)\n",
    "X_scaled_frame = pd.DataFrame(X_scaled,columns=['atr1','atr2','atr3'])\n",
    "print('规格化转换后数据：')\n",
    "print(X_scaled_frame.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "print('绘制3维图：')\n",
    "#创建一个三维的绘图工程\n",
    "fig_3d=plt.figure()\n",
    "ax3d=fig_3d.add_subplot(111,projection='3d') \n",
    "ax3d.scatter(X_scaled_frame['atr1'],X_scaled_frame['atr2'],X_scaled_frame['atr3']) \n",
    "fig_3d.savefig('Section4-3 case_01.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#数据降为2维\n",
    "#在sklearn中提供了PCA函数，可以将高维数据降为低维\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "X_pca_frame = pd.DataFrame(X_pca,columns=['pca_1','pca_2'])\n",
    "print(X_pca_frame.head())\n",
    "print('绘制2维图：')\n",
    "fig_2d=plt.figure()\n",
    "#创建一个二维的绘图工程\n",
    "ax2d=fig_2d.add_subplot(111) \n",
    "ax2d.plot(X_pca_frame['pca_1'],X_pca_frame['pca_2'],'bo') \n",
    "fig_2d.savefig('Section4-3 case_02.png', dpi=300, bbox_inches='tight')\n",
    "fig_2d.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k=4\n",
    "print(\"K均值聚类：\")\n",
    "case_cen, case_clusterAssment = kmeans(X_pca, k)\n",
    "showCluster(X_pca, k, case_cen, case_clusterAssment) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"K中心点聚类：\")\n",
    "case_cen, case_clusterAssment = kmedoids(X_pca, k)\n",
    "showCluster(X_pca, k, case_cen, case_clusterAssment) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#将case_clusterAssment中的聚类结果写回原始DataFrame\n",
    "X_origin['聚类结果']=case_clusterAssment[:,0]\n",
    "print('聚类结果：')\n",
    "print(X_origin.head(15))\n",
    "#查看按照聚类结果分组的各属性均值\n",
    "print('聚类结果按年龄统计均值')\n",
    "g_Age=X_origin['年龄'].groupby(X_origin['聚类结果'])\n",
    "print(g_Age.mean())\n",
    "print('聚类结果按年收入统计均值')\n",
    "g_Income=X_origin['年收入(万元)'].groupby(X_origin['聚类结果'])\n",
    "print(g_Income.mean())\n",
    "print('聚类结果按消费评分统计均值')\n",
    "g_Rate=X_origin['消费评分(1-100)'].groupby(X_origin['聚类结果'])\n",
    "print(g_Rate.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
